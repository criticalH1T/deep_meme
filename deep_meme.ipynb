{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr-4i9bjWA9i",
        "outputId": "4f49f3d1-d3d3-4f44-e035-c3e1509ae007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def download_from_gdrive(gdrive_id, filename):\n",
        "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$gdrive_id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$gdrive_id -O $filename && rm -rf /tmp/cookies.txt\n",
        "\n",
        "import torch\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('DEVICE:', DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "d-euPZ7QWG5Z"
      },
      "outputs": [],
      "source": [
        "GDRIVE_ID = '1S4QwcuznRxLlxkIT0Lb6vIuqDTib41B3'\n",
        "FILE_IDS_NAME = 'file_ids.txt'\n",
        "\n",
        "download_from_gdrive(GDRIVE_ID, FILE_IDS_NAME)\n",
        "\n",
        "FILE_IDS = {}\n",
        "with open(FILE_IDS_NAME, 'r') as f:\n",
        "    for line in f:\n",
        "        name, gid = line.strip().split('\\t')\n",
        "        FILE_IDS[name] = gid\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF-b_IqZWJhM",
        "outputId": "46d7f719-f6e5-4485-944a-d374d3fc0b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading code from GitHub\n",
            "fatal: destination path 'deep_meme' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "print('Loading code from GitHub')\n",
        "!git clone https://github.com/criticalH1T/deep_meme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "m2jluuzJWOeZ"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content')\n",
        "sys.path.append('/content/deep_meme')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "NvB_bsJPWTUw"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = 'memes900k'\n",
        "CAPTIONS_FILE = os.path.join(DATA_DIR, 'captions_train.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "D99QoeMCWWXT"
      },
      "outputs": [],
      "source": [
        "print('Loading the dataset from Google Drive')\n",
        "fname = f'{DATA_DIR}.zip'\n",
        "download_from_gdrive(FILE_IDS[fname], fname)\n",
        "!unzip -o {DATA_DIR}\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Ao9ZvfWZG7",
        "outputId": "43d7de95-cb2a-44aa-b9c0-ccce0fff7fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded vocabularies from Google Drive\n",
            "\n",
            "Vocabulary sizes:\n",
            "WordVocab: 36541\n",
            "CharVocab: 71\n"
          ]
        }
      ],
      "source": [
        "from deep_meme.data.vocab import Vocab, build_vocab_from_file\n",
        "from deep_meme.data.tokenizers import WordPunctTokenizer, CharTokenizer\n",
        "\n",
        "LOAD_VOCABULARY = True #@param {type:\"boolean\"}\n",
        "MIN_DF = 5 #@param {type:\"integer\"}\n",
        "\n",
        "tokenizer_words = WordPunctTokenizer()\n",
        "tokenizer_chars = CharTokenizer()\n",
        "\n",
        "if LOAD_VOCABULARY:\n",
        "    print('Loading vocabularies from Google Drive')\n",
        "\n",
        "    fname = 'vocab.zip'\n",
        "    download_from_gdrive(FILE_IDS[fname], fname)\n",
        "    !unzip -o {fname}\n",
        "\n",
        "    vocab_words = Vocab.load('vocab/vocab_words.txt')\n",
        "    vocab_chars = Vocab.load('vocab/vocab_chars.txt')\n",
        "    clear_output()\n",
        "\n",
        "    print('Loaded vocabularies from Google Drive')\n",
        "else:\n",
        "    print(f'Building WordPunct Vocabulary from {CAPTIONS_FILE}, min_df={MIN_DF}')\n",
        "    vocab_words = build_vocab_from_file(CAPTIONS_FILE, tokenizer_words, min_df=MIN_DF)\n",
        "\n",
        "    print(f'Building Character Vocabulary from {CAPTIONS_FILE}, min_df={MIN_DF}')\n",
        "    vocab_chars = build_vocab_from_file(CAPTIONS_FILE, tokenizer_chars, min_df=MIN_DF)\n",
        "\n",
        "\n",
        "print('\\nVocabulary sizes:')\n",
        "print('WordVocab:', len(vocab_words))\n",
        "print('CharVocab:', len(vocab_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "dv151rV5WchD"
      },
      "outputs": [],
      "source": [
        "from deep_meme.data import MemeDataset\n",
        "\n",
        "# use this to limit the dataset size (300 classes in total)\n",
        "NUM_CLASSES = 200 #@param {type:\"slider\", min:1, max:300, step:1}  \n",
        "PAD_IDX = vocab_words.stoi['<pad>']\n",
        "\n",
        "from torchvision import transforms\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "datasets_words = {\n",
        "    # WORD-LEVEL\n",
        "    split: MemeDataset(DATA_DIR, vocab_words, tokenizer_words, image_transform=image_transform,\n",
        "                       num_classes=NUM_CLASSES, split=split, preload_images=True)\n",
        "    for split in splits\n",
        "}\n",
        "\n",
        "datasets_chars = {\n",
        "    # CHAR-LEVEL\n",
        "    split: MemeDataset(DATA_DIR, vocab_chars, tokenizer_chars, image_transform=image_transform,\n",
        "                       num_classes=NUM_CLASSES, split=split, preload_images=True)\n",
        "    for split in splits\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "swIXXtuNWfw8"
      },
      "outputs": [],
      "source": [
        "from deep_meme.models import (\n",
        "    CaptioningLSTMWithLabels, \n",
        ")\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def load_and_build_model(gdrive_id, ckpt_path, model_class):\n",
        "    print('Downloading model weights from Google Drive')\n",
        "    download_from_gdrive(gdrive_id, ckpt_path)\n",
        "    clear_output()\n",
        "    print('Downloaded model weights')\n",
        "\n",
        "    print(f'Building {model_class.__name__} model')\n",
        "    model = model_class.from_pretrained(ckpt_path).to(DEVICE)\n",
        "    print(f'Built and loaded {model_class.__name__} model from {ckpt_path}')\n",
        "    print('# parameters:', count_parameters(model))\n",
        "\n",
        "    return model\n",
        "\n",
        "FILE_TO_CLASS = {\n",
        "    'LSTMDecoderWithLabelsWords.best.pth': CaptioningLSTMWithLabels,\n",
        "    'LSTMDecoderWithLabelsChars.best.pth': CaptioningLSTMWithLabels,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5faUNInW4DE",
        "outputId": "04086188-778b-4690-992a-9257cf285c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded model weights\n",
            "Building CaptioningLSTMWithLabels model\n",
            "Built and loaded CaptioningLSTMWithLabels model from LSTMDecoderWithLabelsWords.best.pth\n",
            "# parameters: 45333181\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = 'LSTMDecoderWithLabelsWords.best.pth'\n",
        "gdrive_id = FILE_IDS[ckpt_path]\n",
        "model_class = FILE_TO_CLASS[ckpt_path]\n",
        "\n",
        "w_lstm_model_labels = load_and_build_model(gdrive_id, ckpt_path, model_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "8UofnZ9nXCDx"
      },
      "outputs": [],
      "source": [
        "IMG_DIR = 'images_inference'\n",
        "\n",
        "fname = 'inference.zip'\n",
        "download_from_gdrive(FILE_IDS[fname], fname)\n",
        "!unzip -o {fname}\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Moc3juTuXD6z"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from deep_meme.experiments import text_to_seq, seq_to_text, split_caption\n",
        "from deep_meme.imaging import memeify_image\n",
        "FONT_PATH = 'deep_meme/fonts/impact.ttf'\n",
        "\n",
        "def get_a_meme(model, img_torch, img_pil, caption, T=1., beam_size=7, top_k=50, \n",
        "               labels = None, mode = 'word', device=DEVICE):\n",
        "    if mode == 'word':\n",
        "        vocabulary = vocab_words\n",
        "        datasets = datasets_words\n",
        "        delimiter=' '\n",
        "        max_len = 32\n",
        "    else:\n",
        "        vocabulary = vocab_chars\n",
        "        datasets = datasets_chars\n",
        "        delimiter=''\n",
        "        max_len = 128\n",
        "    \n",
        "    model.eval()\n",
        "    if caption is not None:\n",
        "        caption_tensor = torch.tensor(datasets['train']._preprocess_text(caption)[:-1]).unsqueeze(0).to(device) \n",
        "    else:\n",
        "        caption_tensor = None\n",
        "\n",
        "    if labels is None:\n",
        "        with torch.no_grad():\n",
        "            output_seq = model.generate(\n",
        "                image=img_torch, caption=caption_tensor,\n",
        "                max_len=max_len, beam_size=beam_size, temperature=T, top_k=top_k\n",
        "            )\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            output_seq = model.generate(\n",
        "                image=img_torch, label=labels, caption=caption_tensor,\n",
        "                max_len=max_len, beam_size=beam_size, temperature=T, top_k=top_k\n",
        "            )\n",
        "    \n",
        "    pred_seq = output_seq\n",
        "    text = seq_to_text(pred_seq, vocab=vocabulary, delimiter=delimiter)\n",
        "\n",
        "    top, bottom = split_caption(text, num_blocks=2)\n",
        "    # print(top)\n",
        "    # print(bottom)\n",
        "\n",
        "    return memeify_image(img_pil, top, bottom, font_path=FONT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf6vbzY6XaJd"
      },
      "source": [
        "**LSTM MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPmYdi95dlEX"
      },
      "outputs": [],
      "source": [
        "!pip install ColabCode\n",
        "!pip install FastAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "fYW3_Zqfd6XN"
      },
      "outputs": [],
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI\n",
        "from fastapi import Response\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cs9DkF_cd79j"
      },
      "outputs": [],
      "source": [
        "cc = ColabCode(port=12000, code=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "hoA_dvBUzpVK"
      },
      "outputs": [],
      "source": [
        "def get_result(image_id = \"Bad-Luck-Brian\"):\n",
        "  id = image_id.split('-')\n",
        "  label = \" \".join(id)\n",
        "  labels = torch.tensor(datasets_words['train']._preprocess_text(label)).unsqueeze(0).cuda()\n",
        "  img_torch = datasets_words['train'].images[label]\n",
        "  img_pil = Image.open(datasets_words['train'].templates[label])\n",
        "  img_torch = img_torch.unsqueeze(0).cuda()\n",
        "  caption = None # \"Your mom\"\n",
        "  \n",
        "  result = get_a_meme(\n",
        "    model=w_lstm_model_labels, T=1.3, \n",
        "    beam_size=10,\n",
        "    top_k=100,\n",
        "    img_torch=img_torch, \n",
        "    img_pil=img_pil, \n",
        "    caption=caption, \n",
        "    labels=None, \n",
        "    mode='word',\n",
        "    device='cuda'\n",
        "  )\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Sqt0yD02O4"
      },
      "source": [
        "**MODEL DEPLOYMENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "U0pu-LSJeKM5"
      },
      "outputs": [],
      "source": [
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import FileResponse\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"http://localhost\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app.post(\"/\")\n",
        "async def read_root():\n",
        "  return \"Hi\"\n",
        "\n",
        "@app.post(\"/generate\")\n",
        "async def get_image(image_id, response: Response):\n",
        "\n",
        "  print(image_id)\n",
        "  result = get_result(image_id)\n",
        "  result.save(\"out.jpg\", \"JPEG\", quality=100, optimize=True)\n",
        "\n",
        "  # Set response headers and return buffer\n",
        "  response.headers[\"Content-Type\"] = \"image/jpeg\"\n",
        "  return FileResponse(\"out.jpg\", media_type=\"image/jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbLMuXqvhDfi"
      },
      "outputs": [],
      "source": [
        "cc.run_app(app=app)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}